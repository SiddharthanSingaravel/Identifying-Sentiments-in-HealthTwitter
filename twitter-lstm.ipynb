{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Procedure\na. Import the three files (model.h5, model.w2v, tokenizer.pkl) from the mail in the data tab (right panel) and name it as \"input-models\" when uploading in kaggle.\n\nb. Post that, run all code blocks.\n\nc. predict() function will evaluate the sentiment of each text as you enter.\n","metadata":{}},{"cell_type":"code","source":"import time\nimport pickle\nimport numpy as np\nimport keras\nimport tensorflow as tf\n\nprint(f'using keras version... {keras.__version__} & tf version... {tf.__version__}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 1: loading tokenizer\nfrom keras.preprocessing.text import Tokenizer\nTOKENIZER_MODEL = \"../input/input-models/tokenizer.pkl\"\ntokenizer = pickle.load(open(TOKENIZER_MODEL, \"rb\"))  # todo: might want to fix protocol\n\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Total words\", vocab_size)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2: loading w2v model\nfrom gensim.models import KeyedVectors\nfrom keras.layers import Embedding\nw2v_model = KeyedVectors.load(\"../input/input-models/model.w2v\", mmap='r')\nW2V_SIZE = 300\n\nembedding_matrix = np.zeros((vocab_size, W2V_SIZE))\nfor word, i in tokenizer.word_index.items():\n    if word in w2v_model.wv:\n        embedding_matrix[i] = w2v_model.wv[word]\n\nembedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], trainable=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3: loading keras model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM\nfrom keras import utils\n\nmodel = Sequential()\nmodel.add(embedding_layer)\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.load_weights('../input/input-models/model.h5')\nmodel.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nTAG_RE = re.compile(r'<[^>]+>')\n\ndef remove_tags(text):\n    return TAG_RE.sub('', text)\n\n\ndef process_text(sen):\n    # Removing html tags\n    sentence = remove_tags(sen)\n\n    # Remove punctuations and numbers\n    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n\n    # Single character removal\n    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n\n    # Removing multiple spaces\n    sentence = re.sub(r'\\s+', ' ', sentence)\n\n    return sentence","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SENTIMENT\nfrom keras.preprocessing.sequence import pad_sequences\n\nPOSITIVE = \"POSITIVE\"\nNEGATIVE = \"NEGATIVE\"\nNEUTRAL = \"NEUTRAL\"\nSENTIMENT_THRESHOLDS = (0.4, 0.7)\nSEQUENCE_LENGTH = 300\n\ndef decode_sentiment(score, include_neutral=True):\n    if include_neutral:        \n        label = NEUTRAL\n        if score <= SENTIMENT_THRESHOLDS[0]:\n            label = NEGATIVE\n        elif score >= SENTIMENT_THRESHOLDS[1]:\n            label = POSITIVE\n        return label\n    else:\n        return NEGATIVE if score < 0.5 else POSITIVE\n\ndef predict(text, include_neutral=True):\n    start_at = time.time()\n    text = process_text(text)\n    # Tokenize text\n    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n    # Predict\n    score = model.predict([x_test])[0]\n    # Decode sentiment\n    label = decode_sentiment(score, include_neutral=include_neutral)\n\n    return {\"label\": label, \"score\": float(score),\n       \"elapsed_time\": time.time()-start_at}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(text=\"I love the music\", include_neutral=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(text=\"I hate the rain\", include_neutral=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(text=\"Asco 2020 sees multiple myeloma responses deepen\", include_neutral=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}